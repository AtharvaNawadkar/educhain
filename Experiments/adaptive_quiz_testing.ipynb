{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Adaptive_Quiz Class Documentation\n",
        "\n",
        "The `Adaptive_Quiz` class is designed to generate and manage an adaptive quiz that adjusts the difficulty of questions based on the user's responses. This allows for a more personalized learning experience.\n",
        "\n",
        "## Class Overview\n",
        "\n",
        "### Attributes\n",
        "\n",
        "- **`custom_template`**: A template string used to generate a set number of multiple-choice questions (MCQs) based on the provided topic, learning objective, and difficulty level.\n",
        "  \n",
        "- **`adaptive_template`**: A template string used to generate new questions based on the user's response to the previous question. The difficulty of the questions adapts depending on whether the user's response was correct or incorrect.\n",
        "\n",
        "### Constructor (`__init__`)\n",
        "\n",
        "The constructor initializes the `Adaptive_Quiz` object with the following parameters:\n",
        "\n",
        "- **`db`** (`str`): Specifies the database to be used. Default is `None`. If `\"supabase\"` is provided, a connection to Supabase will be initialized.\n",
        "  \n",
        "- **`llm`** (`object`): The language model (LLM) used for generating questions. If not provided, the class will automatically initialize an LLM.\n",
        "  \n",
        "- **`difficulty_increase_threshold`** (`str`): The threshold for increasing the difficulty of questions. Default is `\"Medium\"`.\n",
        "  \n",
        "- **`topic`** (`str`): The topic of the quiz. Default is an empty string (`\"\"`).\n",
        "  \n",
        "- **`num_questions`** (`int`): The number of questions to generate in the quiz. Default is `5`.\n",
        "  \n",
        "- **`custom_instruction`** (`str`): Custom instructions for generating the quiz questions. Default is an empty string (`\"\"`).\n",
        "  \n",
        "- **`show_options`** (`bool`): A boolean indicating whether to immediately show answer options to the user. Default is `False`.\n",
        "  \n",
        "- **`data`** (`any`): External data that might influence question generation. Default is `None`.\n",
        "  \n",
        "- **`source_type`** (`str`): Specifies the source type for quiz data. Default is `None`.\n",
        "\n",
        "### Internal Attributes\n",
        "\n",
        "- **`quiz_data`** (`list`): A list to store the quiz data.\n",
        "  \n",
        "- **`start_time`** (`datetime`): Tracks the start time of the quiz session.\n",
        "  \n",
        "- **`supabase`** (`object`): A connection object to Supabase, initialized if `db` is set to `\"supabase\"`.\n",
        "\n",
        "### Methods\n",
        "\n",
        "#### `initialize_llm()`\n",
        "- **Description**: Initializes the language model (LLM) to be used for generating quiz questions.\n",
        "\n",
        "#### `initialize_supabase()`\n",
        "- **Description**: Initializes a Supabase connection if the `db` parameter is set to `\"supabase\"`.\n",
        "\n",
        "## Example Usage\n",
        "\n",
        "```python\n",
        "quiz = Adaptive_Quiz(\n",
        "    difficulty_increase_threshold=\"High\", #easy/medium/high\n",
        "    topic=\"Mathematics\",\n",
        "    num_questions=10,\n",
        "    custom_instruction=\"Focus on calculus.\",\n",
        "    show_options=True,\n",
        "    data=,\"path/to/data\" #pdf/url/text\n",
        "    source_type=\"URL\" #pdf/url/text\n",
        ")\n"
      ],
      "metadata": {
        "id": "ce1wJ0gI6tp5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing Dependencies"
      ],
      "metadata": {
        "id": "CKZ1oQvF5_9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install educhain langchain_openai supabase --quiet"
      ],
      "metadata": {
        "id": "lrT0elyKgw73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dc45161-3786-4d0e-9765-4de5ad8d7b58"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.0/52.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.5/47.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.9/393.9 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.9/362.9 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m997.8/997.8 kB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.1/149.1 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import Modules"
      ],
      "metadata": {
        "id": "H3gUdynQ6D2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "from educhain import qna_engine\n",
        "from langchain_openai import ChatOpenAI\n",
        "from supabase import create_client, Client\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "cNYwmMo2gr-1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Class Initialization"
      ],
      "metadata": {
        "id": "Jt0ecMv27MJF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Adaptive_Quiz:\n",
        "\n",
        "    custom_template = \"\"\"\n",
        "    Generate {num} multiple-choice question (MCQ) based on the given topic and level.\n",
        "    Provide the question, four answer options, and the correct answer.\n",
        "\n",
        "    Topic: {topic}\n",
        "    Learning Objective: {learning_objective}\n",
        "    Difficulty Level: {difficulty_level}\n",
        "    \"\"\"\n",
        "\n",
        "    adaptive_template = \"\"\"\n",
        "    Based on the user's response to the previous question on {topic}, generate a new multiple-choice question (MCQ).\n",
        "    If the user's response is correct, output a harder question. Otherwise, output an easier question.\n",
        "    Provide the question, four answer options, and the correct answer.\n",
        "\n",
        "    Previous Question: {previous_question}\n",
        "    User's Response: {user_response}\n",
        "    Was the response correct?: {response_correct}\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, db=None, llm=None, difficulty_increase_threshold=\"Medium\", topic=\"\", num_questions=5, custom_instruction=\"\", show_options=False, data=None, source_type=None):\n",
        "        self.db = db\n",
        "        self.llm = llm or self.initialize_llm()\n",
        "        self.difficulty_increase_threshold = difficulty_increase_threshold\n",
        "        self.topic = topic\n",
        "        self.num_questions = num_questions\n",
        "        self.custom_instruction = custom_instruction\n",
        "        self.quiz_data = []\n",
        "        self.start_time = None\n",
        "        self.show_options = show_options\n",
        "        self.data = data\n",
        "        self.source_type = source_type\n",
        "\n",
        "        self.supabase = None\n",
        "        if db == \"supabase\":\n",
        "            self.supabase = self.initialize_supabase()\n",
        "\n",
        "    @staticmethod\n",
        "    def initialize_llm():\n",
        "        api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "        if not api_key:\n",
        "            raise ValueError(\"OPENAI Key not found in environment variables.\")\n",
        "        return ChatOpenAI(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            #openai_api_base=\"https://api.groq.com/openai/v1\",\n",
        "            openai_api_key=api_key\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def initialize_supabase():\n",
        "        url = os.getenv(\"SUPABASE_URL\")\n",
        "        key = os.getenv(\"SUPABASE_KEY\")\n",
        "        if not url or not key:\n",
        "            raise ValueError(\"Supabase URL or Key not found in environment variables.\")\n",
        "        return create_client(url, key)\n",
        "\n",
        "    def generate_initial_question(self):\n",
        "        if self.data:\n",
        "            result = qna_engine.generate_mcqs_from_data(\n",
        "                source=self.data,\n",
        "                source_type=self.source_type,\n",
        "                num=1,\n",
        "                llm=self.llm,\n",
        "            )\n",
        "        else:\n",
        "            result = qna_engine.generate_mcq(\n",
        "                topic=self.topic,\n",
        "                num=1,\n",
        "                learning_objective=f\"General knowledge of {self.topic}\",\n",
        "                difficulty_level=self.difficulty_increase_threshold,\n",
        "                llm=self.llm,\n",
        "                prompt_template=self.custom_template,  # Use self.custom_template\n",
        "            )\n",
        "        return result.questions[0] if result and result.questions else None\n",
        "\n",
        "    def generate_next_question(self, previous_question, user_response, response_correct):\n",
        "        if self.data:\n",
        "            result = qna_engine.generate_mcqs_from_data(\n",
        "                source=self.data,\n",
        "                source_type=self.source_type,\n",
        "                num=1,\n",
        "                llm=self.llm,\n",
        "            )\n",
        "        else:\n",
        "            result = qna_engine.generate_mcq(\n",
        "                topic=self.topic,\n",
        "                num=1,\n",
        "                llm=self.llm,\n",
        "                prompt_template=self.adaptive_template,  # Use self.adaptive_template\n",
        "                previous_question=previous_question,\n",
        "                user_response=user_response,\n",
        "                response_correct=response_correct\n",
        "            )\n",
        "        return result.questions[0] if result and result.questions else None\n",
        "\n",
        "    def start_quiz(self):\n",
        "        self.start_time = time.time()\n",
        "        question_number = 0\n",
        "        score = 0\n",
        "\n",
        "        current_question = self.generate_initial_question()\n",
        "        while question_number < self.num_questions and current_question:\n",
        "            print(f\"Question {question_number + 1}: {current_question.question}\")\n",
        "            if self.show_options:\n",
        "                for i, option in enumerate(current_question.options):\n",
        "                    print(f\"{i+1}. {option}\")\n",
        "                user_answer = input(\"Select the correct option number: \")\n",
        "                user_answer = current_question.options[int(user_answer) - 1]\n",
        "            else:\n",
        "                user_answer = input(\"Your answer: \")\n",
        "            correct_answer = current_question.answer\n",
        "\n",
        "            if user_answer == correct_answer:\n",
        "                print(\"Correct!\")\n",
        "                score += 1\n",
        "                response_correct = \"True\"\n",
        "            else:\n",
        "                print(f\"Incorrect. The correct answer was {correct_answer}.\")\n",
        "                response_correct = \"False\"\n",
        "\n",
        "            # Log quiz data\n",
        "            self.quiz_data.append({\n",
        "                \"question_number\": question_number + 1,\n",
        "                \"question\": current_question.question,\n",
        "                \"user_answer\": user_answer,\n",
        "                \"correct_answer\": correct_answer,\n",
        "                \"response_correct\": response_correct,\n",
        "            })\n",
        "\n",
        "            # Generate the next question\n",
        "            question_number += 1\n",
        "            current_question = self.generate_next_question(\n",
        "                current_question.question,\n",
        "                user_answer,\n",
        "                response_correct\n",
        "            )\n",
        "\n",
        "        total_time = time.time() - self.start_time\n",
        "        print(f\"Quiz completed! Final Score: {score}/{self.num_questions}. Total Time: {total_time:.2f} seconds\")\n",
        "\n",
        "        if self.supabase:\n",
        "            self.save_to_supabase(score, total_time)\n",
        "\n",
        "    def save_to_supabase(self, score, total_time):\n",
        "        try:\n",
        "            data = {\n",
        "                \"topic\": self.topic,\n",
        "                \"difficulty_increase_threshold\": self.difficulty_increase_threshold,\n",
        "                \"num_questions\": self.num_questions,\n",
        "                \"score\": score,\n",
        "                \"total_time\": total_time,\n",
        "                \"quiz_data\": self.quiz_data\n",
        "            }\n",
        "            print(data)\n",
        "            response = self.supabase.table(\"quiz_results\").insert(data).execute()\n",
        "            if response.status_code != 201:\n",
        "                raise Exception(f\"Failed to save quiz data to Supabase. Response: {response.data}\")\n",
        "            print(\"Quiz data successfully saved to Supabase.\")\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred while saving to Supabase: {e}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Nkwxp0ppf7I7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Use Case\n",
        "if __name__ == \"__main__\":\n",
        "    quiz = Adaptive_Quiz(\n",
        "        topic=\"Python Programming\",\n",
        "        num_questions=3\n",
        "    )\n",
        "    quiz.start_quiz()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNcF1mfn6nM6",
        "outputId": "c11e83ff-56d0-48b1-c6e3-bfcde19875df"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question 1: What is the output of the following code: print(type([]) is list)?\n",
            "Your answer: list\n",
            "Incorrect. The correct answer was True.\n",
            "Question 2: What will the following code output? print(5 // 2)\n",
            "Your answer: 2\n",
            "Correct!\n",
            "Question 3: What will the following code output? print(3 ** 2)\n",
            "Your answer: 9\n",
            "Correct!\n",
            "Quiz completed! Final Score: 2/3. Total Time: 30.61 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Added Data support as well"
      ],
      "metadata": {
        "id": "4Fwn9QgUgr5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "quiz = Adaptive_Quiz(\n",
        "    topic=\"Python\",\n",
        "    num_questions=1,\n",
        "    show_options=True,\n",
        "    data=\"https://en.wikipedia.org/wiki/Python_(programming_language)\",\n",
        "    source_type=\"url\"\n",
        ")\n",
        "quiz.start_quiz()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OmvZ8TggcFD",
        "outputId": "67e0d9db-ac90-4698-edd1-c2cef3b86348"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question 1: What is the primary design philosophy of Python?\n",
            "1. Code complexity over simplicity\n",
            "2. Code readability and simplicity\n",
            "3. Using punctuation over whitespace for structure\n",
            "4. Strictly enforcing static typing\n",
            "Select the correct option number: 3\n",
            "Incorrect. The correct answer was Code readability and simplicity.\n",
            "Quiz completed! Final Score: 0/1. Total Time: 12.37 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Routine Testing"
      ],
      "metadata": {
        "id": "4BquFrZJgt8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    quiz = Adaptive_Quiz(\n",
        "\n",
        "        topic=\"Python Programming\",\n",
        "        num_questions=1\n",
        "\n",
        "    )\n",
        "    quiz.start_quiz()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyhjIOjWgx-g",
        "outputId": "62b96d66-9225-4803-9f6a-b9f268009b94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question 1: What is the output of the following code: print(type([]) is list)?\n",
            "Your answer: list\n",
            "Incorrect. The correct answer was True.\n",
            "Quiz completed! Final Score: 0/1. Total Time: 8.80 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "  ## Accessing native functions"
      ],
      "metadata": {
        "id": "XGkWKxjsjjlh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "quiz = Adaptive_Quiz(\n",
        "    topic=\"Python\",\n",
        "    num_questions=5,\n",
        "    show_options=True,\n",
        ")\n",
        "\n",
        "question = quiz.generate_initial_question()\n",
        "print(question.question)\n",
        "print(question.options)\n",
        "print(question.answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RBegfrziNzs",
        "outputId": "f770b5ea-4409-4b72-f3f1-e6aba0183960"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is the output of the following Python code: print(type([]) is list)?\n",
            "['True', 'False', 'None', 'TypeError']\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Rx8xIFQiNxk",
        "outputId": "fa26da40-1a25-43f0-be05-69cc1d4f708b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the output of the following Python code: print(type([]) is list)?\n",
            "Options:\n",
            "  A. True\n",
            "  B. False\n",
            "  C. None\n",
            "  D. TypeError\n",
            "\n",
            "Correct Answer: True\n",
            "Explanation: In Python, the 'type' function returns the type of an object. Since '[]' is an empty list, 'type([])' returns 'list', and comparing it with 'list' using 'is' will return True.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IWg2eNGGiNva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hwPNgV65iNtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PlqKiphNiNqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mRpOXIAgiNom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m4Yok1f4iNmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S8fLjQGdiNj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "niWrFmOniNhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl --request GET \\\n",
        "     --url https://api.play.ht/api/v2/voices \\\n",
        "     --header 'accept: application/json'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8xDzD0miNe5",
        "outputId": "33ade93e-d210-45f4-e11a-f1a3f37463fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"error_message\":\"An authorization header must be provided. Please refer to https://docs.play.ht/reference/api-authentication for more info.\",\"error_id\":\"UNAUTHORIZED\"}"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Supabase Integration Testing"
      ],
      "metadata": {
        "id": "0fRorRIoofp9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%env SUPABASE_URL = \"URL\"\n",
        "\n",
        "%env SUPABASE_KEY = \"KEY\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SD3v3Ea4mHle",
        "outputId": "fc3d4172-d5ff-4ab2-f555-21b613a60cd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: SUPABASE_URL=\"URL\"\n",
            "env: SUPABASE_KEY=\"KEY\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    quiz = Adaptive_Quiz(\n",
        "        db = 'supabase',\n",
        "        topic=\"Python Programming\",\n",
        "        num_questions=1\n",
        "\n",
        "    )\n",
        "    quiz.start_quiz()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXNW8T7MkUAe",
        "outputId": "5e93bb68-475f-4951-f86a-3ab441642ca3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question 1: What is the output of the following Python code: print(type([]))?\n",
            "Your answer: list\n",
            "Correct!\n",
            "Quiz completed! Final Score: 1/1. Total Time: 6.05 seconds\n",
            "{'topic': 'Python Programming', 'difficulty_increase_threshold': 'Medium', 'num_questions': 1, 'score': 1, 'total_time': 6.051225423812866, 'quiz_data': [{'question_number': 1, 'question': 'What is the output of the following Python code: print(type([]))?', 'user_answer': 'list', 'correct_answer': 'list', 'response_correct': 'True'}]}\n",
            "An error occurred while saving to Supabase: {}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L4SIgjyaoVfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SQL SCHEMA Creation"
      ],
      "metadata": {
        "id": "NXCAYmCdoV9p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import json\n",
        "from educhain import qna_engine\n",
        "from langchain_openai import ChatOpenAI\n",
        "from supabase import create_client, Client\n",
        "\n",
        "class Adaptive_Quiz:\n",
        "    custom_template = \"\"\"\n",
        "    Generate {num} multiple-choice question (MCQ) based on the given topic and level.\n",
        "    Provide the question, four answer options, and the correct answer.\n",
        "\n",
        "    Topic: {topic}\n",
        "    Learning Objective: {learning_objective}\n",
        "    Difficulty Level: {difficulty_level}\n",
        "    \"\"\"\n",
        "\n",
        "    adaptive_template = \"\"\"\n",
        "    Based on the user's response to the previous question on {topic}, generate a new multiple-choice question (MCQ).\n",
        "    If the user's response is correct, output a harder question. Otherwise, output an easier question.\n",
        "    Provide the question, four answer options, and the correct answer.\n",
        "\n",
        "    Previous Question: {previous_question}\n",
        "    User's Response: {user_response}\n",
        "    Was the response correct?: {response_correct}\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, db=None, llm=None, difficulty_increase_threshold=\"Medium\", topic=\"\", num_questions=5, custom_instruction=\"\"):\n",
        "        self.db = db\n",
        "        self.llm = llm or self.initialize_llm()\n",
        "        self.difficulty_increase_threshold = difficulty_increase_threshold\n",
        "        self.topic = topic\n",
        "        self.num_questions = num_questions\n",
        "        self.custom_instruction = custom_instruction\n",
        "        self.quiz_data = []\n",
        "        self.start_time = None\n",
        "\n",
        "        self.supabase = None\n",
        "        if db == \"supabase\":\n",
        "            self.supabase = self.initialize_supabase()\n",
        "            self.create_table_if_not_exists()\n",
        "\n",
        "    @staticmethod\n",
        "    def initialize_llm():\n",
        "        api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "        if not api_key:\n",
        "            raise ValueError(\"GROQ API Key not found in environment variables.\")\n",
        "        return ChatOpenAI(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            openai_api_base=\"https://api.groq.com/openai/v1\",\n",
        "            openai_api_key=api_key\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def initialize_supabase():\n",
        "        url = os.getenv(\"SUPABASE_URL\")\n",
        "        key = os.getenv(\"SUPABASE_KEY\")\n",
        "        if not url or not key:\n",
        "            raise ValueError(\"Supabase URL or Key not found in environment variables.\")\n",
        "        return create_client(url, key)\n",
        "\n",
        "    def create_table_if_not_exists(self):\n",
        "        create_table_sql = \"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS quiz_results (\n",
        "            id SERIAL PRIMARY KEY,\n",
        "            topic TEXT NOT NULL,\n",
        "            difficulty_increase_threshold TEXT NOT NULL,\n",
        "            num_questions INTEGER NOT NULL,\n",
        "            score INTEGER NOT NULL,\n",
        "            total_time FLOAT NOT NULL,\n",
        "            quiz_data JSONB NOT NULL,\n",
        "            created_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP\n",
        "        );\n",
        "        \"\"\"\n",
        "        try:\n",
        "            response = self.supabase.rpc(\"execute_sql\", {\"query\": create_table_sql}).execute()\n",
        "            print(\"Table creation response:\", response)\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred while creating the table: {e}\")\n",
        "\n",
        "    def generate_initial_question(self):\n",
        "        result = qna_engine.generate_mcq(\n",
        "            topic=self.topic,\n",
        "            num=1,\n",
        "            learning_objective=f\"General knowledge of {self.topic}\",\n",
        "            difficulty_level=self.difficulty_increase_threshold,\n",
        "            llm=self.llm,\n",
        "            prompt_template=self.custom_template,\n",
        "        )\n",
        "        return result.questions[0] if result and result.questions else None\n",
        "\n",
        "    def generate_next_question(self, previous_question, user_response, response_correct):\n",
        "        result = qna_engine.generate_mcq(\n",
        "            topic=self.topic,\n",
        "            num=1,\n",
        "            llm=self.llm,\n",
        "            prompt_template=self.adaptive_template,\n",
        "            previous_question=previous_question,\n",
        "            user_response=user_response,\n",
        "            response_correct=response_correct\n",
        "        )\n",
        "        return result.questions[0] if result and result.questions else None\n",
        "\n",
        "    def start_quiz(self):\n",
        "        self.start_time = time.time()\n",
        "        question_number = 0\n",
        "        score = 0\n",
        "\n",
        "        current_question = self.generate_initial_question()\n",
        "        while question_number < self.num_questions and current_question:\n",
        "            print(f\"Question {question_number + 1}: {current_question.question}\")\n",
        "            user_answer = input(\"Your answer: \")\n",
        "            correct_answer = current_question.answer\n",
        "\n",
        "            if user_answer == correct_answer:\n",
        "                print(\"Correct!\")\n",
        "                score += 1\n",
        "                response_correct = \"True\"\n",
        "            else:\n",
        "                print(f\"Incorrect. The correct answer was {correct_answer}.\")\n",
        "                response_correct = \"False\"\n",
        "\n",
        "            # Log quiz data\n",
        "            self.quiz_data.append({\n",
        "                \"question_number\": question_number + 1,\n",
        "                \"question\": current_question.question,\n",
        "                \"user_answer\": user_answer,\n",
        "                \"correct_answer\": correct_answer,\n",
        "                \"response_correct\": response_correct,\n",
        "            })\n",
        "\n",
        "            # Generate the next question\n",
        "            question_number += 1\n",
        "            current_question = self.generate_next_question(\n",
        "                current_question.question,\n",
        "                user_answer,\n",
        "                response_correct\n",
        "            )\n",
        "\n",
        "        total_time = time.time() - self.start_time\n",
        "        print(f\"Quiz completed! Final Score: {score}/{self.num_questions}. Total Time: {total_time:.2f} seconds\")\n",
        "\n",
        "        if self.supabase:\n",
        "            self.save_to_supabase(score, total_time)\n",
        "\n",
        "    def save_to_supabase(self, score, total_time):\n",
        "        try:\n",
        "            data = {\n",
        "                \"topic\": self.topic,\n",
        "                \"difficulty_increase_threshold\": self.difficulty_increase_threshold,\n",
        "                \"num_questions\": self.num_questions,\n",
        "                \"score\": score,\n",
        "                \"total_time\": total_time,\n",
        "                \"quiz_data\": json.dumps(self.quiz_data)  # Ensure quiz_data is JSON-encoded\n",
        "            }\n",
        "\n",
        "            # Print the data being sent to Supabase for debugging purposes\n",
        "            print(\"Saving the following data to Supabase:\", data)\n",
        "\n",
        "            response = self.supabase.table(\"quiz_results\").insert(data).execute()\n",
        "\n",
        "            # Print the response from Supabase for debugging purposes\n",
        "            print(\"Supabase response:\", response)\n",
        "\n",
        "            if response.status_code != 201:\n",
        "                raise Exception(f\"Failed to save quiz data to Supabase. Response: {response.data}\")\n",
        "            print(\"Quiz data successfully saved to Supabase.\")\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred while saving to Supabase: {e}\")\n",
        "\n",
        "# Example Use Case\n",
        "if __name__ == \"__main__\":\n",
        "    quiz = Adaptive_Quiz(\n",
        "        db=\"supabase\",\n",
        "        topic=\"Python Programming\",\n",
        "        num_questions=1\n",
        "    )\n",
        "    quiz.start_quiz()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "sGwtkukcmMT2",
        "outputId": "85fdcbf2-70a4-473c-f750-b07ad956be52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An error occurred while creating the table: {'code': 'PGRST202', 'details': 'Searched for the function public.execute_sql with parameter query or with a single unnamed json/jsonb parameter, but no matches were found in the schema cache.', 'hint': None, 'message': 'Could not find the function public.execute_sql(query) in the schema cache'}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AuthenticationError",
          "evalue": "Error code: 401 - {'error': {'message': 'Invalid API Key', 'type': 'invalid_request_error', 'code': 'invalid_api_key'}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-7ae69eb5dd72>\u001b[0m in \u001b[0;36m<cell line: 172>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mnum_questions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     )\n\u001b[0;32m--> 178\u001b[0;31m     \u001b[0mquiz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_quiz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-25-7ae69eb5dd72>\u001b[0m in \u001b[0;36mstart_quiz\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mcurrent_question\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_initial_question\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mquestion_number\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_questions\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcurrent_question\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Question {question_number + 1}: {current_question.question}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-7ae69eb5dd72>\u001b[0m in \u001b[0;36mgenerate_initial_question\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_initial_question\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         result = qna_engine.generate_mcq(\n\u001b[0m\u001b[1;32m     83\u001b[0m             \u001b[0mtopic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mnum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/educhain/qna_engine.py\u001b[0m in \u001b[0;36mgenerate_mcq\u001b[0;34m(topic, num, llm, response_model, prompt_template, custom_instructions, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mMCQ_chain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMCQ_prompt\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     results = MCQ_chain.invoke(\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;34m{\u001b[0m\u001b[0;34m\"num\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"topic\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtopic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2876\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2877\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2878\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2879\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2880\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    274\u001b[0m         return cast(\n\u001b[1;32m    275\u001b[0m             \u001b[0mChatGeneration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    277\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    774\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    775\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m     async def agenerate_prompt(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                     \u001b[0mrun_managers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m         flattened_outputs = [\n\u001b[1;32m    635\u001b[0m             \u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_output\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[list-item]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    621\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m                 results.append(\n\u001b[0;32m--> 623\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    624\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m                         \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    843\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m                 result = self._generate(\n\u001b[0m\u001b[1;32m    846\u001b[0m                     \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mgeneration_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"headers\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_chat_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeneration_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    666\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m    667\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    669\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1258\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         )\n\u001b[0;32m-> 1260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    935\u001b[0m         \u001b[0mstream_cls\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_StreamT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m     ) -> ResponseT | _StreamT:\n\u001b[0;32m--> 937\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    938\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1039\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m         return self._process_response(\n",
            "\u001b[0;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'message': 'Invalid API Key', 'type': 'invalid_request_error', 'code': 'invalid_api_key'}}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AJGteFiLoPhy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}